{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "listed-allergy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "ssc = StreamingContext(sc, 5)\n",
    "\n",
    "lines = KafkaUtils.createDirectStream(ssc,\n",
    "                                      topics=['Demo-Topic'],\n",
    "                                      kafkaParams={ 'metadata.broker.list': 'server-pd:9092' })\n",
    "\n",
    "lines.pprint()\n",
    "# 데이터 처리\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legal-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conventional-might",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "settled-parameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "ssc = StreamingContext(sc, 5)\n",
    "\n",
    "lines = KafkaUtils.createDirectStream(ssc,\n",
    "                                      topics=['Demo-Topic'],\n",
    "                                      kafkaParams={ 'metadata.broker.list': 'server-pd:9092' })\n",
    "\n",
    "# 데이터 처리\n",
    "# (None, ...)\n",
    "rows = lines.map(lambda line: line[1].split(','))\n",
    "rows.pprint()\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "virtual-camel",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-liability",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "def processRDD(rdd):\n",
    "    row = rdd.map(lambda line: line[1].split(','))\n",
    "    if row.count() > 0:\n",
    "        df = spark.createDataFrame(row)\n",
    "        df.show()\n",
    "    else:\n",
    "        print(\"no data received\")\n",
    "\n",
    "ssc = StreamingContext(sc, 5)\n",
    "\n",
    "lines = KafkaUtils.createDirectStream(ssc,\n",
    "                                      topics=['Demo-Topic'],\n",
    "                                      kafkaParams={ 'metadata.broker.list': 'server-pd:9092' })\n",
    "\n",
    "# 데이터 처리\n",
    "# (None, ...)\n",
    "lines.foreachRDD(processRDD)\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "realistic-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-sleeve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-heaven",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "def processRDD(rdd):\n",
    "    row = rdd.map(lambda line: line[1].split(','))\n",
    "    if row.count() > 0:\n",
    "        df = spark.createDataFrame(row, [\"date\", 'car_number', 'speed_pedal', 'break_pedal', 'steer_angle', 'direct_light', 'speed', 'area_number'])\n",
    "        df.show()\n",
    "    else:\n",
    "        print(\"no data received\")\n",
    "\n",
    "\n",
    "ssc = StreamingContext(sc, 5)\n",
    "\n",
    "lines = KafkaUtils.createDirectStream(ssc,\n",
    "                                      topics=['SmartCar-Topic'],\n",
    "                                      kafkaParams={ 'metadata.broker.list': 'server-pd:9092' })\n",
    "\n",
    "# 데이터 처리\n",
    "# (None, ...)\n",
    "# lines.pprint()\n",
    "lines.foreachRDD(processRDD)\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "noted-danish",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-canada",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-salvation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no data received\n",
      "no data received\n",
      "no data received\n",
      "no data received\n",
      "no data received\n",
      "no data received\n",
      "no data received\n",
      "no data received\n",
      "no data received\n"
     ]
    }
   ],
   "source": [
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "\n",
    "# hbase에  'DriverCarInfo' 테이블을 만들고 다음을 실행 ( create 'DriverCarInfo', 'cf1' )\n",
    "\n",
    "catalog = ''.join(\"\"\"{\n",
    "    \"table\":{ \"namespace\": \"default\", \"name\": \"DriverCarInfo\" },\n",
    "    \"rowkey\": \"key\",\n",
    "    \"columns\": {\n",
    "        \"key\": { \"cf\": \"rowkey\", \"col\": \"key\", \"type\": \"string\" },\n",
    "        \"date\": { \"cf\": \"cf1\", \"col\": \"date\", \"type\": \"string\" }, \n",
    "        \"car_number\": { \"cf\": \"cf1\", \"col\": \"car_number\", \"type\": \"string\" }, \n",
    "        \"speed_pedal\": { \"cf\": \"cf1\", \"col\": \"speed_pedal\", \"type\": \"string\" }, \n",
    "        \"break_pedal\": { \"cf\": \"cf1\", \"col\": \"break_pedal\", \"type\": \"string\" }, \n",
    "        \"steer_angle\": { \"cf\": \"cf1\", \"col\": \"steer_angle\", \"type\": \"string\" }, \n",
    "        \"direct_light\": { \"cf\": \"cf1\", \"col\": \"direct_light\", \"type\": \"string\" }, \n",
    "        \"speed\": { \"cf\": \"cf1\", \"col\": \"speed\", \"type\": \"string\" }, \n",
    "        \"area_number\": { \"cf\": \"cf1\", \"col\": \"area_number\", \"type\": \"string\" }\n",
    "    }\n",
    "}\"\"\".split())\n",
    "\n",
    "def makeRow(line):\n",
    "    row = line[1].split(',') # 'a,b,c,d' -> ['a', 'b', 'c', 'd']\n",
    "    row2 = [ row[0] + \"-\" + row[1] ] + row # [ 'a' + '-' + 'b' ] + ['a', 'b', 'c', 'd'] -> ['a-b', 'a', 'b', 'c', 'd']\n",
    "    return row2\n",
    "\n",
    "\n",
    "def processRDD(rdd):\n",
    "    row = rdd.map(makeRow) # row = rdd.map(lambda line: line[1].split(','))\n",
    "    if row.count() > 0:\n",
    "        df = spark.createDataFrame(row, [\"key\", \"date\", 'car_number', 'speed_pedal', 'break_pedal', 'steer_angle', 'direct_light', 'speed', 'area_number'])\n",
    "        df.write \\\n",
    "          .option('catalog', catalog) \\\n",
    "          .format('org.apache.spark.sql.execution.datasources.hbase') \\\n",
    "          .save()\n",
    "        \n",
    "        print('data processed !!!!')\n",
    "    else:\n",
    "        print(\"no data received\")\n",
    "\n",
    "\n",
    "ssc = StreamingContext(sc, 5)\n",
    "\n",
    "lines = KafkaUtils.createDirectStream(ssc,\n",
    "                                      topics=['SmartCar-Topic'],\n",
    "                                      kafkaParams={ 'metadata.broker.list': 'server-pd:9092' })\n",
    "\n",
    "# 데이터 처리\n",
    "# (None, ...)\n",
    "# lines.pprint()\n",
    "lines.foreachRDD(processRDD)\n",
    "\n",
    "ssc.start()\n",
    "ssc.awaitTermination()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "weird-stocks",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-anxiety",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
